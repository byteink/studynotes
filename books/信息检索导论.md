# 前沿
第一章：倒排索引    
第二章：建立索引之前对文本如何预处理；讨论在不同功能和速度要求下对倒排索引的改进    
第三章：词典搜索结构；处理有拼写错误的查询、与文档集合中的词汇不能精确匹配的处理    
第四章：对大规模文档建立分布式可扩展的倒排索引的算法   
第五章：词典和倒排索引的压缩   
前五张只能处理精确匹配，要么匹配要么不匹配，而不能量化匹配程度、打分等    
第六七章：rank-ordered   
第八章：介绍如何评价一个信息检索系统，可以对不同的系统进行对比   
       
第九章：使用相关性反馈和查询扩展等技术提高返回相关文档的可能性   
第十章：对类似xml、html结构化的标记语言进行检索    
第十一章：概率检索模型    
    
# 第一章 布尔检索
结构化数据如关系数据库；非结构化数据如文本；   
半结构化数据如网页（具有格式标记如标题、段落、注脚）   
信息检索也需要支持半结构化数据，如查找标题中含有java且正文中含有threading的文档。   
    
term是索引的单位。term不一定是word，比如Hong kong就不是一个word。    

倒排记录：    
dictionary（词项） -> posting list 或者叫 invert list （倒排记录表）   
所有的倒排记录一起构成全体倒排记录表（postings）    
dictionary按照字母顺序排序，posting list按照文档ID排序（方便在O(N)时间内求交集）。    
    
多个词项取交集时，可以按照词项的文档频率（即倒排记录表的长度）排序，优先合并两个最短的(并不一定是最优的）   
    
和bool retrieval mode相对的是ranked retrieval models（如vector space model）   
这种模型可以使用 free text queries，比如随意输入一两个单词而不是精确的表达式。    
bool的模型还可以加入 term proximity 操作符，用于限定两个词项在文档中应该相互靠近。    
靠近程度根据两者之间的词个数或者是否同在一个结构单元（在一个句子或段落）来衡量。   

# 第二章 词项字典及倒排记录表
倒排索引建立的步骤：    
收集文档 -> Tokenize -> 对tokens进行语言学处理 -> 按照term进行索引   
    
索引粒度（index granularity）：precision 正确率 和recall 召回率 之间的平衡    
粒度太小：term分布在多个细粒度的小文档里，可能忽略重要的段落，即正确率高，召回率低；    
粒度太大：可能找到很多不相关的匹配。即正确率低，召回率高；   
粒度过大导致的问题也可以通过显式或隐式的临近搜索（proximity search）方法来缓解。   
   
Tokenization：将字符序列转换成一个个token。   
主要任务是确定哪些是正确的token，往往与语言本身有关。   
对于大多数语言特别是一些特定领域的语言来说，往往有一些特定的tokens需要识别为term，比如C++。   
一些特殊类型的字符串序列也需要识别为单独的token，比如email地址、ip地址。    
还有一些不需要索引比如数字、货币量，不然索引词汇量会很大（特例：邮件发送的日期）。    
对于汉字需要先进行分词，另外一种方法是抛弃word-based索引采用短字符序列的方式（例如K-gram）。    
这种方式不用关心token是否跨越词的边界。    
    
停用词：stop word    
某些情况下一些常用词用于匹配的价值不大，需要从文档中去除。这些词成为停用词。    
一种常用的方式是根据term在文档出现的频率排序，选择跟文档主题关系不大的高频词作为停用词。    
不对停用词进行索引有可能对短语查询造成影响。例如文章名为As we may think，如果只针对think进行索引，搜索会很困难。  
    
                                                                     
                                                                               
词项归一化 Normalization：     
查询中的token有可能跟文档中的token不完全一致，例如查询USA希望返回包含U.S.A的文档。     
token normalization就是将看起来不完全一致的tokens归纳为一个等价类。     
最常规的做法是隐式地建立等价类equivalence classes。例如可以使用去掉连字符的映射规则来构建等价类。     
     
另一种建立等价类的方法是维护多个unnormalized tokens之间关联关系，可以进一步扩展为手工构建同义词词表，     
可以对unnormalized token建立索引，查询时对查询词进行扩展 query expansion（节省空间，查询处理耗费时间）；     
也可以在索引构建时就进行扩展建立多个索引（浪费空间）。     
     
隐式建立等价类或者查询扩展的使用程度是一个开放的问题，过度使用很容易无意间造成非预期的扩展结果。     
     
归一化会遇到的问题：     
- 重音和变音符号     
- 大小写转换问题  通常全部转换为小写
- 英语中的其他问题  英式美式不同的拼写方式、日期时间和其他对象具有不同的形式
- 其他语言问题   同一个文档内可能有不同的语言
      
        
              
Stemming 和 lemmatization  词干还原和词形归并：    
词干还原：很粗略地去除单词两端词缀的启发式处理。常常也包含去除派生词缀    
         一般情况下合并单词的派生形式。    
词形归并：通常指利用词汇表和词形分析来去除屈折词缀，返回词的原型或词典中的词，返回的结果成为词元（lemma）    
                  通常只合并词元的不同屈折形式。     
这两者往往通过在索引过程中增加插件的方式来实现。     
英语处理中最常用的词干还原算法是Porter算法。     
其他算法如单遍扫描的Lovins算法、较新的Paice/Husk算法。     
词干还原能够提高召回率但是会降低正确率。                        

      
基于跳表的倒排记录表快速合并算法：      
建立索引的时候在posting list上增加 skip pointer。     
适用于索引变化（更新）不太频繁的场景。           
     
     
     
      
